{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b85d8232",
   "metadata": {},
   "source": [
    "\"\"\"\n",
    "CSE 5526 (Spring 2026)\n",
    "HW1 – Question 5\n",
    "\n",
    "Students must implement:\n",
    "  1) perceptron_update\n",
    "  2) train_perceptron\n",
    "\n",
    "All other code is provided.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edc421e9",
   "metadata": {},
   "source": [
    "1. Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b064a258",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98f5ceaa",
   "metadata": {},
   "source": [
    "2. Load and prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6414a652",
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = datasets.load_iris()\n",
    "X = iris[\"data\"][:, (2, 3)].astype(float)   # petal length, petal width\n",
    "d = (iris[\"target\"] == 0).astype(int)       # 1 = Setosa, 0 = non-Setosa\n",
    "\n",
    "N, D = X.shape\n",
    "\n",
    "# Shuffle once\n",
    "rng = np.random.default_rng(42)\n",
    "perm = rng.permutation(N)\n",
    "X = X[perm]\n",
    "d = d[perm]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fcfd622",
   "metadata": {},
   "source": [
    "3. Plot input space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4bbd38f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.grid(True)\n",
    "plt.plot(X[d == 0, 0], X[d == 0, 1], \"o\", label=\"d=0 (non-Setosa)\")\n",
    "plt.plot(X[d == 1, 0], X[d == 1, 1], \"x\", label=\"d=1 (Setosa)\")\n",
    "plt.xlabel(\"Petal Length\")\n",
    "plt.ylabel(\"Petal Width\")\n",
    "plt.title(\"Iris Input Space\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf6a8c37",
   "metadata": {},
   "source": [
    "4. Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de1608f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def step(net: float) -> int:\n",
    "    \"\"\"Binary step activation.\"\"\"\n",
    "    return 1 if net >= 0 else 0\n",
    "\n",
    "\n",
    "def predict_all(X: np.ndarray, w: np.ndarray, b: float) -> np.ndarray:\n",
    "    \"\"\"Predict class labels for all samples.\"\"\"\n",
    "    nets = X @ w + b\n",
    "    return np.array([step(v) for v in nets], dtype=int)\n",
    "\n",
    "\n",
    "def accuracy(y_hat: np.ndarray, y_true: np.ndarray) -> float:\n",
    "    return float(np.mean(y_hat == y_true))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14400402",
   "metadata": {},
   "source": [
    "5. TODO : Perceptron learning rule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4feb514",
   "metadata": {},
   "outputs": [],
   "source": [
    "def perceptron_update(\n",
    "    x_i: np.ndarray,\n",
    "    d_i: int,\n",
    "    w: np.ndarray,\n",
    "    b: float,\n",
    "    eta: float\n",
    "):\n",
    "    \"\"\"\n",
    "    Perform ONE perceptron update.\n",
    "\n",
    "    Inputs:\n",
    "        x_i : shape (2,) input vector\n",
    "        d_i : desired output (0 or 1)\n",
    "        w   : current weight vector, shape (2,)\n",
    "        b   : current bias (scalar)\n",
    "        eta : learning rate\n",
    "\n",
    "    Outputs:\n",
    "        w_new : updated weight vector, shape (2,)\n",
    "        b_new : updated bias (scalar)\n",
    "        error : (d_i - y_i), expected to be in {-1, 0, +1}\n",
    "    \"\"\"\n",
    "\n",
    "    # TODO (students):\n",
    "    #   1) Compute net = w·x_i + b\n",
    "    #   2) Compute y_i = step(net)\n",
    "    #   3) Compute error = d_i - y_i\n",
    "    #   4) Update using the perceptron learning rule:\n",
    "    #        w_new = w + eta * error * x_i\n",
    "    #        b_new = b + eta * error\n",
    "\n",
    "    return w_new, b_new, error\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66e44a70",
   "metadata": {},
   "source": [
    "6. TODO : Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd027a81",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_perceptron(\n",
    "    X: np.ndarray,\n",
    "    d: np.ndarray,\n",
    "    eta: float,\n",
    "    max_epochs: int\n",
    "):\n",
    "    \"\"\"\n",
    "    Train a perceptron using the perceptron learning rule.\n",
    "\n",
    "    Inputs:\n",
    "        X          : shape (N,2) input matrix\n",
    "        d          : shape (N,) desired outputs (0 or 1)\n",
    "        eta        : learning rate\n",
    "        max_epochs : maximum number of epochs\n",
    "\n",
    "    Outputs:\n",
    "        w : learned weight vector, shape (2,)\n",
    "        b : learned bias (scalar)\n",
    "        mistakes_per_epoch : list of number of misclassified samples per epoch\n",
    "    \"\"\"\n",
    "\n",
    "    N, D = X.shape\n",
    "    w = np.zeros(D)\n",
    "    b = 0.0\n",
    "\n",
    "    mistakes_per_epoch = []\n",
    "\n",
    "    # TODO (students):\n",
    "    #   for each epoch:\n",
    "    #       mistakes = 0\n",
    "    #       for each training sample i:\n",
    "    #           w, b, error = perceptron_update(X[i], d[i], w, b, eta)\n",
    "    #           Count a mistake when y_i != d_i (equivalently, when error != 0)\n",
    "    #       mistakes_per_epoch.append(mistakes)\n",
    "    #       stop early if mistakes == 0\n",
    "\n",
    "    return w, b, mistakes_per_epoch\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49c534c5",
   "metadata": {},
   "source": [
    "7. Run training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f3d2cfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "eta = 0.1\n",
    "max_epochs = 100\n",
    "\n",
    "w, b, mistakes_per_epoch = train_perceptron(X, d, eta, max_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34b26317",
   "metadata": {},
   "source": [
    "8. Evaluate performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3286cd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat = predict_all(X, w, b)\n",
    "acc = accuracy(y_hat, d)\n",
    "\n",
    "print(f\"Final training accuracy: {acc:.4f}\")\n",
    "print(f\"Final weights: w = {w}\")\n",
    "print(f\"Final bias: b = {b}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "539f9406",
   "metadata": {},
   "source": [
    "9. Decision boundary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d067719",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nDecision boundary:\")\n",
    "print(f\"{w[0]:.6f} * x1 + {w[1]:.6f} * x2 + {b:.6f} = 0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac9bc962",
   "metadata": {},
   "source": [
    "10. Plot decision boundary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0594748",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.grid(True)\n",
    "plt.plot(X[d == 0, 0], X[d == 0, 1], \"o\", label=\"d=0\")\n",
    "plt.plot(X[d == 1, 0], X[d == 1, 1], \"x\", label=\"d=1\")\n",
    "\n",
    "x1_min, x1_max = X[:, 0].min() - 0.5, X[:, 0].max() + 0.5\n",
    "xs = np.linspace(x1_min, x1_max, 200)\n",
    "\n",
    "# Decision boundary: w1*x1 + w2*x2 + b = 0\n",
    "# If w2 != 0: x2 = -(w1/w2)*x1 - (b/w2)\n",
    "# If w2 == 0 and w1 != 0: vertical line at x1 = -b/w1\n",
    "if abs(w[1]) > 1e-12:\n",
    "    ys = -(w[0] / w[1]) * xs - (b / w[1])\n",
    "    plt.plot(xs, ys)\n",
    "else:\n",
    "    if abs(w[0]) > 1e-12:\n",
    "        x_vert = -b / w[0]\n",
    "        plt.axvline(x_vert)\n",
    "    else:\n",
    "        print(\"Warning: both weights are ~0; cannot plot a meaningful decision boundary.\")\n",
    "\n",
    "plt.xlabel(\"Petal Length\")\n",
    "plt.ylabel(\"Petal Width\")\n",
    "plt.legend()\n",
    "plt.title(\"Perceptron Decision Boundary\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1356124",
   "metadata": {},
   "source": [
    "11. Mistakes vs epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "967cd849",
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(mistakes_per_epoch) > 0:\n",
    "    plt.figure()\n",
    "    plt.grid(True)\n",
    "    plt.plot(np.arange(1, len(mistakes_per_epoch) + 1), mistakes_per_epoch)\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Mistakes\")\n",
    "    plt.title(\"Training Mistakes per Epoch\")\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"mistakes_per_epoch is empty (training loop not implemented yet).\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
