{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b85d8232",
   "metadata": {},
   "source": [
    "\"\"\"\n",
    "CSE 5526 (Spring 2026)\n",
    "HW1 â€“ Question 5\n",
    "\n",
    "Students must implement:\n",
    "  1) step\n",
    "  2) perceptron_update\n",
    "  3) train_perceptron\n",
    "  4) plotting decision boundary\n",
    "\n",
    "All other code is provided.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edc421e9",
   "metadata": {},
   "source": [
    "1. Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b064a258",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98f5ceaa",
   "metadata": {},
   "source": [
    "2. Load and prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6414a652",
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = datasets.load_iris()\n",
    "X = iris[\"data\"][:, (2, 3)].astype(float)   # petal length, petal width\n",
    "d = (iris[\"target\"] == 0).astype(int)       # 1 = Setosa, 0 = non-Setosa\n",
    "\n",
    "N, D = X.shape\n",
    "\n",
    "# Shuffle once\n",
    "rng = np.random.default_rng(42)\n",
    "perm = rng.permutation(N)\n",
    "X = X[perm]\n",
    "d = d[perm]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fcfd622",
   "metadata": {},
   "source": [
    "3. Plot input space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4bbd38f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.grid(True)\n",
    "plt.plot(X[d == 0, 0], X[d == 0, 1], \"o\", label=\"d=0 (non-Setosa)\")\n",
    "plt.plot(X[d == 1, 0], X[d == 1, 1], \"x\", label=\"d=1 (Setosa)\")\n",
    "plt.xlabel(\"Petal Length\")\n",
    "plt.ylabel(\"Petal Width\")\n",
    "plt.title(\"Iris Input Space\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf6a8c37",
   "metadata": {},
   "source": [
    "4. TODO : Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de1608f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def step(net: float) -> int:\n",
    "    \"\"\"\n",
    "    Binary step activation function.\n",
    "\n",
    "    Input:\n",
    "        net : net input to the neuron (scalar)\n",
    "\n",
    "    Output:\n",
    "        y : binary output (0 or 1)\n",
    "    \"\"\"\n",
    "    # TODO (students): implement a binary step function\n",
    "    pass\n",
    "\n",
    "\n",
    "def predict_all(X: np.ndarray, w: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Predict class labels for all samples.\n",
    "\n",
    "    Notes:\n",
    "        - The bias is included as w[0].\n",
    "        - Inputs are augmented as x_aug = [1, x1, x2].\n",
    "        - Net input: net = w^T x_aug\n",
    "    \"\"\"\n",
    "    N = X.shape[0]\n",
    "    X_aug = np.hstack([np.ones((N, 1)), X])  # shape (N, 3)\n",
    "    nets = X_aug @ w\n",
    "    return np.array([step(v) for v in nets], dtype=int)\n",
    "\n",
    "\n",
    "def accuracy(y_hat: np.ndarray, y_true: np.ndarray) -> float:\n",
    "    \"\"\"\n",
    "    Compute classification accuracy.\n",
    "    \"\"\"\n",
    "    return float(np.mean(y_hat == y_true))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14400402",
   "metadata": {},
   "source": [
    "5. TODO : Perceptron learning rule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4feb514",
   "metadata": {},
   "outputs": [],
   "source": [
    "def perceptron_update(\n",
    "    x_i: np.ndarray,\n",
    "    d_i: int,\n",
    "    w: np.ndarray,\n",
    "    eta: float\n",
    "):\n",
    "    \"\"\"Perform ONE perceptron update using a single training sample.\n",
    "\n",
    "    Inputs:\n",
    "        x_i : shape (2,) input vector = [x1, x2]\n",
    "        d_i : desired output (0 or 1)\n",
    "        w   : current weight vector INCLUDING bias, shape (3,)\n",
    "              w[0] is the bias weight\n",
    "              w[1] corresponds to x1, w[2] corresponds to x2\n",
    "        eta : learning rate\n",
    "\n",
    "    Outputs:\n",
    "        w_new : updated weight vector, shape (3,)\n",
    "        error : calculated error\n",
    "    \"\"\"\n",
    "    # TODO (students): implement perceptron learning rule update\n",
    "    return w_new, error\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66e44a70",
   "metadata": {},
   "source": [
    "6. TODO : Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd027a81",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_perceptron(\n",
    "    X: np.ndarray,\n",
    "    d: np.ndarray,\n",
    "    eta: float,\n",
    "    max_steps: int\n",
    "):\n",
    "    \"\"\"\n",
    "    Train a perceptron using the perceptron learning rule.\n",
    "\n",
    "    NOTE:\n",
    "      - Training is organized by STEPS (iterations), not epochs.\n",
    "      - At step t, one training sample is selected).\n",
    "      - The bias is included as part of the weight vector.\n",
    "      - Plot step/iteration vs error to monitor the training\n",
    "\n",
    "    Inputs:\n",
    "        X         : shape (N,2) input matrix\n",
    "        d         : shape (N,) desired outputs (0 or 1)\n",
    "        eta       : learning rate\n",
    "        max_steps : maximum number of update steps/iterations\n",
    "\n",
    "    Outputs:\n",
    "        w : learned weight vector INCLUDING bias, shape (3,)\n",
    "            w[0] is the bias weight (multiplies constant input 1)\n",
    "            w[1] corresponds to x1\n",
    "            w[2] corresponds to x2\n",
    "    \"\"\"\n",
    "\n",
    "    N, D = X.shape\n",
    "    assert D == 2\n",
    "\n",
    "    # Initialize weights (including bias as w[0])\n",
    "    w = np.zeros(D + 1)\n",
    "\n",
    "    # TODO (students): implement training loop in steps/iterations\n",
    "\n",
    "    return w"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49c534c5",
   "metadata": {},
   "source": [
    "7. Run training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f3d2cfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "eta = 0.1\n",
    "max_steps = 500\n",
    "\n",
    "w = train_perceptron(X, d, eta, max_steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34b26317",
   "metadata": {},
   "source": [
    "8. Evaluate performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3286cd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat = predict_all(X, w)\n",
    "acc = accuracy(y_hat, d)\n",
    "\n",
    "print(f\"Final training accuracy: {acc:.4f}\")\n",
    "print(f\"Final weights (bias included as w[0]): w = {w}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "539f9406",
   "metadata": {},
   "source": [
    "9. Decision boundary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d067719",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nDecision boundary:\")\n",
    "print(\"w0*1 + w1*x1 + w2*x2 = 0\")\n",
    "print(f\"{w[0]:.6f}*1 + {w[1]:.6f}*x1 + {w[2]:.6f}*x2 = 0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac9bc962",
   "metadata": {},
   "source": [
    "10. TODO : Plot decision boundary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0594748",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO (students):\n",
    "# Plot the training samples and the perceptron decision boundary.\n",
    "#\n",
    "# Requirements:\n",
    "#   - Plot the two classes in the input space (petal length vs. petal width).\n",
    "#   - Use the learned weights and bias to plot the decision boundary.\n",
    "#   - Clearly label axes, legend, and title.\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
